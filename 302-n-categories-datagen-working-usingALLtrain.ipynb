{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## setup\n",
    "import os\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "sys.setrecursionlimit(3000)\n",
    "K.set_image_dim_ordering('th')\n",
    "pd.set_option('max_colwidth', 400)\n",
    "np.core.arrayprint._line_width = 999\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "# img_width, img_height = 256, 256\n",
    "\n",
    "# create labels dictionary\n",
    "\n",
    "df_train = pd.read_csv('/Users/NoSlack/kaggle_planet/train.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "n_label = len(label_map)\n",
    "\n",
    "len(df_train)\n",
    "\n",
    "# create train data in x_train y_train\n",
    "x_train = []\n",
    "y_train = []\n",
    "for f, tags in tqdm(df_train.values, miniters=10):\n",
    "    img = cv2.imread('/Users/NoSlack/kaggle_planet/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(n_label)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (128, 128)))\n",
    "    y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float16) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# create df_test\n",
    "x_test = []\n",
    "testdir = os.listdir('/Users/NoSlack/kaggle_planet/test-jpg/')\n",
    "jpgdir = [test for test in testdir if '.jpg' in test]\n",
    "df_test = pd.DataFrame()\n",
    "df_test['image_name'] = [jpg.replace('.jpg','') for jpg in jpgdir]\n",
    "df_test['tags'] = 0\n",
    "\n",
    "# load test data in x_test\n",
    "for f, tags in tqdm(df_test.values, miniters=10):\n",
    "    img = cv2.imread('/Users/NoSlack/kaggle_planet/test-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(n_label)\n",
    "    \n",
    "    x_test.append(cv2.resize(img, (128, 128)))\n",
    "    \n",
    "x_test = np.array(x_test, np.float16) / 255.\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "## create model using weights\n",
    "model_load = Sequential()\n",
    "model_load.add(ZeroPadding2D((1, 1), input_shape=(3, 128, 128)))\n",
    "\n",
    "model_load.add(Convolution2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "model_load.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "model_load.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "model_load.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "model_load.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "model_load.add(ZeroPadding2D((1, 1)))\n",
    "model_load.add(Convolution2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "model_load.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model_load.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "#     weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    weights = []\n",
    "    for p in range(g.attrs['nb_params']):\n",
    "        if len(g['param_{}'.format(p)].shape) > 1:\n",
    "            weights.append(np.transpose(g['param_{}'.format(p)], (2,3,1,0)))\n",
    "        else:\n",
    "            weights.append(g['param_{}'.format(p)])\n",
    "    \n",
    "    model_load.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "x_train_transform = np.zeros((40479,512,4,4))\n",
    "for xn in tqdm(range(40479)):\n",
    "    im = x_train[xn]\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    im_transform = model_load.predict(im)\n",
    "    x_train_transform[xn] = im_transform\n",
    "\n",
    "x_test_transform = np.zeros((61191,512,4,4))\n",
    "for xn in tqdm(range(61191)):\n",
    "    im = x_test[xn]\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    im_transform = model_load.predict(im)\n",
    "    x_test_transform[xn] = im_transform\n",
    "\n",
    "# split validation off train data\n",
    "split = 40000\n",
    "x_train0, x_valid0, y_train0, y_valid0 = x_train_transform[:split], x_train_transform[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "## train and save weights\n",
    "model_train = Sequential()\n",
    "model_train.add(Flatten(input_shape=x_train_transform.shape[1:]))\n",
    "model_train.add(Dense(256, activation='relu'))\n",
    "model_train.add(Dropout(0.5))\n",
    "model_train.add(Dense(n_label, activation='sigmoid'))\n",
    "#model_train.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_train.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "            \n",
    "model_train.fit(x_train0, y_train0,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid0, y_valid0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make predictions\n",
    "data_to_predict = x_test_transform\n",
    "p_test = model_train.predict(data_to_predict, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create label list from probablity list\n",
    "final_p = p_test\n",
    "preds = [' '.join([inv_label_map[y_pred_pos] for y_pred_pos, y_pred in enumerate(\n",
    "    (y_pred_row > 0.1).astype(int))  if y_pred==1]) for y_pred_row in final_p]\n",
    "\n",
    "# create submission file\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
